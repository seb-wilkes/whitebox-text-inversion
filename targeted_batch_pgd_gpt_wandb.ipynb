{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NGxOSNMApeh0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/vedang/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# !pip install wandb optuna\n",
        "import typing as t\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from torch.optim import Adam, AdamW, Optimizer\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "import dataclasses\n",
        "import optuna\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import types\n",
        "from typing import Callable\n",
        "import wandb\n",
        "\n",
        "PROJECT = \"whitebox-inversion\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vVxjKOVOqJnv"
      },
      "outputs": [],
      "source": [
        "\n",
        "@dataclasses.dataclass\n",
        "class Config:\n",
        "    # Core\n",
        "    prefix: str = \"Hello! Will you marry me?\"\n",
        "    suffix_length: int = 13\n",
        "    seed: int = 42*69*69\n",
        "    batch_size: int = 500\n",
        "    randomise: bool = False\n",
        "    add_eos: bool = False\n",
        "    relax_hot_val: float = 0.01\n",
        "    model_id = \"gpt2\"\n",
        "\n",
        "  # Learning\n",
        "    learning_rate: float = 2e-3\n",
        "    iterations: int = 500\n",
        "    optimizer: str = \"adam\"\n",
        "    scheduler_t_0: int = 28\n",
        "\n",
        "    # Entropy projection\n",
        "    start_entropy: float = 1.\n",
        "    stop_entropy: float = 1.\n",
        "\n",
        "    # Re-initialization\n",
        "    reinit_threshold: int = 0\n",
        "    reinit_rand_alpha: float = 1e-4\n",
        "    reinit_blend_alpha: float = 1e-2\n",
        "\n",
        "    # Blending\n",
        "    best_blend_alpha: float = 0\n",
        "    best_blend_threshold: float = 0.05\n",
        "\n",
        "    # Discrete sampling\n",
        "    discrete_sampling_temp: float = 2.0\n",
        "\n",
        "    # Optuna\n",
        "    use_optuna: bool = False\n",
        "    optuna_trials: int = 10\n",
        "    optuna_storage: str = \"sqlite:///optuna.db\"\n",
        "    optuna_study_name: str = PROJECT\n",
        "\n",
        "    # Wandb\n",
        "    wandb_logging: bool = True\n",
        "\n",
        "def adapt_for_optuna(config: Config, trial: optuna.Trial) -> Config:\n",
        "    config.wandb_logging = False\n",
        "    config.suffix_length = trial.suggest_int(\"suffix_length\", 1, 30)\n",
        "    config.relax_hot_val = trial.suggest_float(\"relax_hot_val\", 0.001, 0.1)\n",
        "    config.learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True)\n",
        "    config.optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"adamw\"])\n",
        "    config.scheduler_t_0 = trial.suggest_int(\"scheduler_t_0\", 5, 30)\n",
        "    config.stop_entropy = trial.suggest_float(\"stop_entropy\", 0.99, 1.0)\n",
        "    config.reinit_threshold = trial.suggest_int(\"reinit_threshold\", 0, 300, step=10)\n",
        "    config.best_blend_alpha = trial.suggest_float(\"best_blend_alpha\", 0, 0.1)\n",
        "    config.best_blend_threshold = trial.suggest_float(\"best_blend_threshold\", 0, 0.1)\n",
        "    config.discrete_sampling_temp = trial.suggest_float(\"discrete_sampling_temp\", 1.0, 3.0)\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mNoi3SYDdcym"
      },
      "outputs": [],
      "source": [
        "def get_model_wrapper(model_id: str, maximum_layer: int = None, keep_head: bool = False, device=\"cuda\") -> nn.Module:\n",
        "    if maximum_layer is not None:\n",
        "        return truncate_model(model_id, maximum_layer, keep_head, device), \\\n",
        "            AutoTokenizer.from_pretrained(model_id)\n",
        "    else:\n",
        "        return AutoModelForCausalLM.from_pretrained(model_id).to(device=device), \\\n",
        "            AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "def truncate_model(model_id: str, maximum_layer: int, keep_head: bool = False, device=\"cuda\") -> nn.Module:\n",
        "    '''This truncates the LM up to the target layer, meaning\n",
        "    that inference is faster. As such the output of model.generate\n",
        "    will be the desired activation layer'''\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "\n",
        "    if hasattr(model, 'transformer') and hasattr(model.transformer, 'h'):\n",
        "        # Truncate the list of layers\n",
        "        model.transformer.h = nn.ModuleList(model.transformer.h[:maximum_layer + 1])\n",
        "\n",
        "        # Adjust the config to reflect the new number of layers\n",
        "        if hasattr(model.config, 'num_hidden_layers'):\n",
        "            model.config.num_hidden_layers = maximum_layer + 1\n",
        "\n",
        "        if not keep_head:\n",
        "             # Remove the language model head if desired\n",
        "            if hasattr(model, 'lm_head'):\n",
        "                delattr(model, 'lm_head')\n",
        "\n",
        "            # The final layer norm seems important to smooth running\n",
        "            # however, we can replace it with an identity function\n",
        "            if hasattr(model.transformer, 'ln_f'):\n",
        "                model.transformer.ln_f = nn.Identity(model.transformer.ln_f.normalized_shape)\n",
        "\n",
        "        # Modify the forward method to return the output of the last transformer block\n",
        "        def new_forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, output_attentions=None, output_hidden_states=None, return_dict=None):\n",
        "            outputs = self.transformer(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids,\n",
        "                position_ids=position_ids,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "            return outputs[0]  # Return the last hidden state directly\n",
        "\n",
        "        model.forward = types.MethodType(new_forward, model)\n",
        "    else:\n",
        "        raise ValueError(\"Model structure not as expected. Please check the model architecture.\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GIY3TTvTaEfZ"
      },
      "outputs": [],
      "source": [
        "def maximise_entropy_distribution_of_layer(activations, numerical_safety=1e-4):\n",
        "    # Our goal is to get the layer to uniformally (>0) fire\n",
        "    # by taking the abs, we get a worst case normalisation\n",
        "    normaliser = torch.abs(activations).sum(dim=1).unsqueeze(1)\n",
        "    # take a relu to only get positive values; normalising it\n",
        "    # in this way promotes anti-sparsity\n",
        "    p_activations = (torch.nn.functional.relu(activations) + 1e-4) / normaliser\n",
        "    log_p_activations = torch.log(p_activations)\n",
        "    losses = torch.nn.functional.kl_div(log_p_activations, \\\n",
        "                               (torch.ones(p_activations.shape[1])/p_activations.shape[1]).to(activations.device), \\\n",
        "                                        reduction='none') # preserves batch dims\n",
        "\n",
        "    return losses.sum(dim=1)\n",
        "\n",
        "def return_maximise_layer_entropy_distribution(numerical_safety=1e-4):\n",
        "    _loss_wraper = lambda activations: maximise_entropy_distribution_of_layer(activations, numerical_safety=numerical_safety)\n",
        "    return _loss_wraper\n",
        "\n",
        "def maximise_entropy_distribution_of_logits(activations, unembedding_weights, numerical_safety=1e-4):\n",
        "    # This method is similar to the activation layer optimisation\n",
        "    # but this time we are deliberately trying to make it such that the logits\n",
        "    # are maximally activated\n",
        "    logits = (unembedding_weights@activations.T).T\n",
        "    # by taking the abs, we get a worst case normalisation\n",
        "    normaliser = torch.abs(logits).sum()\n",
        "    # take a relu to only get positive values\n",
        "    p_activations = (torch.nn.functional.relu(logits) + 1e-4) / normaliser\n",
        "    log_p_activations = torch.log(p_activations)\n",
        "    losses = torch.nn.functional.kl_div(log_p_activations, \\\n",
        "                               (torch.ones(p_activations.shape[1])/p_activations.shape[1]).to(activations.device), \\\n",
        "                                        reduction='none') # preserves batch dims\n",
        "\n",
        "    return losses.sum(dim=1)\n",
        "\n",
        "def return_maximise_logit_entropy_distribution(model_id, numerical_safety=1e-4, device=\"cuda\"):\n",
        "    _model, _ = get_model_wrapper(model_id, device=device)\n",
        "    unembedding_weights = _model.lm_head.weight\n",
        "    _loss_wraper = lambda activations: maximise_entropy_distribution_of_logits(activations, unembedding_weights, numerical_safety=numerical_safety)\n",
        "    return _loss_wraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E6vxWIVaIV3P"
      },
      "outputs": [],
      "source": [
        "def to_relaxed_one_hot(tokens: torch.Tensor, vocab_size: int, hot_val: float = 1.0) -> torch.Tensor:\n",
        "    batch_size, seq_len = tokens.size()\n",
        "    one_hot = torch.zeros(batch_size, seq_len, vocab_size, device=tokens.device)\n",
        "    one_hot.scatter_(2, tokens.unsqueeze(-1).to(torch.int64), hot_val)\n",
        "    remaining_prob = hot_val / (vocab_size - 1)\n",
        "    one_hot += remaining_prob * (1 - one_hot)\n",
        "    return one_hot.to(tokens.device)\n",
        "\n",
        "def simplex_projection(tensor: torch.Tensor) -> torch.Tensor:\n",
        "    d_batch, d_tokens, d_vocab = tensor.shape\n",
        "    mu, _ = torch.sort(tensor, descending=True, dim=-1)\n",
        "    cumulative = mu.cumsum(dim=-1)\n",
        "    indices = torch.arange(1, d_vocab + 1, device=tensor.device).expand(d_batch, d_tokens, -1).float()\n",
        "    threshold = (cumulative - 1) / indices\n",
        "    rho = (mu > threshold).sum(dim=-1) - 1\n",
        "\n",
        "    # Ensure rho doesn't go out of bounds\n",
        "    rho = torch.clamp(rho, 0, d_vocab - 1)\n",
        "\n",
        "    # Calculate threshold for each row\n",
        "    threshold_per_row = torch.gather(threshold, 2, rho.unsqueeze(-1))  # Shape: [batch_size, seq_len, 1]\n",
        "    projected = torch.max(tensor - threshold_per_row, torch.zeros_like(tensor))\n",
        "    return projected\n",
        "\n",
        "def entropy_projection(tensor: torch.Tensor, entropy: float) -> torch.Tensor:\n",
        "    positive_mask = (tensor > 0).float()\n",
        "    positive_count = positive_mask.sum(dim=-1, keepdim=True)\n",
        "    c = positive_mask / positive_count\n",
        "    R = torch.sqrt(1 - entropy - 1 / (positive_count))\n",
        "    if R.isnan().any():\n",
        "        return tensor\n",
        "    norm_s_c = torch.norm(tensor - c, dim=-1, keepdim=True)\n",
        "    needs_projection = (norm_s_c < R).float()\n",
        "    does_not_need_projection = 1 - needs_projection\n",
        "    scaled_s = torch.where(needs_projection.bool(), (R / norm_s_c) * (tensor - c) + c, tensor)\n",
        "    projection = simplex_projection(scaled_s)\n",
        "    result = does_not_need_projection * tensor + needs_projection * projection\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4C0U2Pe6r0CJ"
      },
      "outputs": [],
      "source": [
        "def attack(model: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, config: Config, loss_func: Callable, verbose: bool = False, discrete_loss_sample_rate: int = 1) -> t.Tuple[float, torch.Tensor]:\n",
        "    device = next(model.parameters()).device\n",
        "    optimizer: Optimizer\n",
        "\n",
        "    if config.optimizer == \"adamw\":\n",
        "        optimizer = AdamW([torch.zeros(1, device=device)], lr=config.learning_rate)\n",
        "    elif config.optimizer == \"adam\":\n",
        "        optimizer = Adam([torch.zeros(1, device=device)], lr=config.learning_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid optimizer: {config.optimizer}\")\n",
        "\n",
        "    prefix_str = config.prefix if config.prefix else \"\"\n",
        "\n",
        "    suffix_tokens = torch.randint(low=0, high=tokenizer.vocab_size, size=(config.batch_size, config.suffix_length), device=\"cpu\")\n",
        "    prefix_tokens = tokenizer.encode(prefix_str, return_tensors='pt').squeeze(0).repeat(config.batch_size, 1).to(\"cpu\")\n",
        "\n",
        "    all_tokens = torch.cat([prefix_tokens, suffix_tokens], dim=1).to(device)\n",
        "    suffix_slice = slice(prefix_tokens.shape[1], all_tokens.shape[1])\n",
        "\n",
        "    labels = all_tokens.clone().type(torch.int64)\n",
        "    labels[:, :suffix_slice.stop] = -100 # signals to be ignored\n",
        "    labels = labels[:,1:].flatten(start_dim=0,end_dim=1) # ready for CE loss\n",
        "\n",
        "    inputs = to_relaxed_one_hot(all_tokens, tokenizer.vocab_size, hot_val=config.relax_hot_val)\n",
        "    if config.randomise:\n",
        "        # extra randomness that is NOT limited to the token plane\n",
        "        random_values = torch.rand_like(inputs[:,suffix_slice])\n",
        "        normalized_values = random_values / random_values.sum(dim=-1, keepdim=True)\n",
        "        inputs[:,suffix_slice] = normalized_values\n",
        "\n",
        "    inputs.requires_grad_()\n",
        "\n",
        "    optimizer.param_groups.clear()\n",
        "    optimizer.add_param_group({\"params\": [inputs]})\n",
        "\n",
        "    # Collect relevant dimensions assuming inputs has shape\n",
        "    # [batch_size, sequence_length, vocab_size]\n",
        "    batch_size, prediction_seq_length, vocab_size = config.batch_size, \\\n",
        "    inputs.shape[1] - 1, tokenizer.vocab_size\n",
        "\n",
        "    scheduler = CosineAnnealingLR(optimizer, config.scheduler_t_0)\n",
        "\n",
        "    best_loss = torch.inf * torch.ones(1, device=device)\n",
        "    best_discrete = None\n",
        "    current_entropy = config.start_entropy\n",
        "    entropy_delta = (config.stop_entropy - config.start_entropy) / config.iterations\n",
        "\n",
        "    for i in tqdm(range(1, config.iterations + 1)):\n",
        "        input_embeds = (inputs @ model.transformer.wte.weight).to(device)\n",
        "        # Assuming input_embeds has shape [batch_size, sequence_length, embedding_dim]\n",
        "        # we take the final\n",
        "        activations = (model(inputs_embeds=input_embeds))[:, -1, :]\n",
        "        # Calculate loss\n",
        "        loss = loss_func(activations)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        dummy_grad = torch.ones_like(loss)\n",
        "        loss.backward(gradient=dummy_grad)\n",
        "\n",
        "        inputs.grad.data[:, : suffix_slice.start] = 0\n",
        "        inputs.grad.data[:, suffix_slice.stop :] = 0\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        inputs.data[:, suffix_slice] = simplex_projection(inputs.data[:, suffix_slice])\n",
        "        if current_entropy != 1.0:\n",
        "            inputs.data[:, suffix_slice] = entropy_projection(inputs.data[:, suffix_slice], current_entropy)\n",
        "        current_entropy += entropy_delta\n",
        "        discrete = torch.argmax(inputs.data[:, suffix_slice], dim=2)\n",
        "        all_tokens[:, suffix_slice] = discrete\n",
        "        if verbose or config.wandb_logging:\n",
        "          save_loss = loss.detach().cpu().mean()\n",
        "        del activations, loss # release memory\n",
        "        # collect and potentially print outputs\n",
        "        if i % discrete_loss_sample_rate == 0:\n",
        "            with torch.no_grad():\n",
        "                activations_discrete = (model(all_tokens))[:, -1]\n",
        "                discrete_loss = loss_func(activations_discrete)\n",
        "                avg_loss_i, avg_best_loss = discrete_loss.mean(), best_loss.mean()\n",
        "                if avg_loss_i < avg_best_loss:\n",
        "                    best_loss = discrete_loss\n",
        "                    best_discrete = discrete\n",
        "            if verbose:\n",
        "                current_discrete_text = [tokenizer.decode(x) for x in discrete[:3]]\n",
        "                print(f\"[{i}] L-rel: {save_loss:.5f} / L-dis: {discrete_loss.flatten().mean():.5f} / Best: {best_loss.flatten().mean():.5f}\")\n",
        "                print(f\" |- Curr: {current_discrete_text}\")\n",
        "\n",
        "            if config.wandb_logging:\n",
        "                wandb.log({\n",
        "                    \"iteration\": i,\n",
        "                    \"relaxed_loss\": save_loss,\n",
        "                    \"avg_discrete_loss\": avg_best_loss.item(),\n",
        "                    \"avg_best_loss\": avg_best_loss.item(),\n",
        "                    \"current_entropy\": current_entropy,\n",
        "                    \"learning_rate\": scheduler.get_last_lr()[0],\n",
        "                })\n",
        "            del activations_discrete, discrete_loss # release memory\n",
        "\n",
        "    return best_loss, best_discrete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GKhJ8iy-qk4C"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    config = Config()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if config.wandb_logging and not config.use_optuna:\n",
        "        wandb.init(project=PROJECT, config=dataclasses.asdict(config))\n",
        "\n",
        "    print(\"[+] Loading model and tokenizer...\")\n",
        "    # instanciate model\n",
        "    t_model, t_toke = get_model_wrapper(config.model_id, 6)\n",
        "    # load in desired loss function\n",
        "    loss_e = return_maximise_logit_entropy_distribution(config.model_id)\n",
        "\n",
        "    if config.use_optuna:\n",
        "        print(\"[+] Using Optuna ...\")\n",
        "        study = optuna.create_study(\n",
        "            study_name=config.optuna_study_name,\n",
        "            storage=config.optuna_storage,\n",
        "            direction=\"minimize\",\n",
        "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30, interval_steps=10),\n",
        "        )\n",
        "        study.optimize(\n",
        "            lambda trial: attack(t_model, t_toke, adapt_for_optuna(config, trial))[0],\n",
        "            n_trials=config.optuna_trials,\n",
        "        )\n",
        "        print(\"Best trial:\")\n",
        "        trial = study.best_trial\n",
        "        print(\"  Value: \", trial.value)\n",
        "        print(\"  Params: \")\n",
        "        for key, value in trial.params.items():\n",
        "            print(\"    {}: {}\".format(key, value))\n",
        "    else:\n",
        "        print(\"[+] Start Attack ...\")\n",
        "        loss, best_prompt = attack(t_model, t_toke, config, loss_e, verbose=config.wandb_logging, discrete_loss_sample_rate=1)\n",
        "        print()\n",
        "        print(\"[+] Done. Final loss:\", loss.mean())\n",
        "        print(\"[*] Done. Example best prompt:\", t_toke.decode(best_prompt[0]))  # Decode only the first batch item\n",
        "        print()\n",
        "\n",
        "    if config.wandb_logging:\n",
        "        wandb.finish()\n",
        "\n",
        "    return best_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGLCl4ghqlTW",
        "outputId": "77420798-cd4b-4857-ce55-f49d2b32548f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvedang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/vedang/whitebox-inversion/wandb/run-20240716_160042-smjw76jo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vedang/whitebox-inversion/runs/smjw76jo' target=\"_blank\">crimson-eon-49</a></strong> to <a href='https://wandb.ai/vedang/whitebox-inversion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/vedang/whitebox-inversion' target=\"_blank\">https://wandb.ai/vedang/whitebox-inversion</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/vedang/whitebox-inversion/runs/smjw76jo' target=\"_blank\">https://wandb.ai/vedang/whitebox-inversion/runs/smjw76jo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Loading model and tokenizer...\n",
            "[+] Start Attack ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1] L-rel: 19.55417 / L-dis: 19.12102 / Best: 19.12102\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista productive', 'ULToberifies comparisonTOlivion 163ques Valencia Book tastingtube plurality', ' horrifyingkillingscriptioneps Hardingwiceventsserviceimum Overs Fist angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/500 [00:01<05:14,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2] L-rel: 19.38756 / L-dis: 19.12102 / Best: 19.12102\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista productive', 'ULToberifies comparisonTOlivion 163ques Valencia Book tastingtube plurality', ' horrifyingkillingscriptioneps Hardingwiceventsserviceimum Overs Fist angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/500 [00:01<04:31,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3] L-rel: 19.29544 / L-dis: 19.07581 / Best: 19.07581\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Vim', 'ULToberifies comparisonTOlivion 163ques Valencia Book FIL Hero plurality', ' horrifyingkillingscriptioneps Hardingwiceventsserviceimum Overs Awesome angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 4/500 [00:02<04:10,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4] L-rel: 19.29736 / L-dis: 19.08939 / Best: 19.07581\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Crimson', 'ULToberifies comparisonTOlivion 163ques Valencia Book criticize bureaucrats plurality', ' horrifyingkillingscriptioneps Hardingwiceventsserviceimum Oversmillion angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 5/500 [00:02<03:59,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5] L-rel: 19.28969 / L-dis: 19.04700 / Best: 19.04700\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Crimson', 'ULToberifies comparisonTOlivion 163ques Valencia Book Glover FIL Leg', ' horrifyingkillingscriptioneps Hardingwiceventsserviceimum Oversmillion angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 6/500 [00:03<03:52,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6] L-rel: 19.27999 / L-dis: 19.00017 / Best: 19.00017\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Crimson', ' Ciroberifies comparisonTOlivion 163ques Valencia Bookviews FIL Leg', ' horrifyingkilling Flyerseps Hardingwiceventsserviceimum Oversiked angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▏         | 7/500 [00:03<03:47,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7] L-rel: 19.26879 / L-dis: 18.95240 / Best: 18.95240\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Signsoberifies comparisonTOlivion 163ques Valencia Bookviews™ Leg', ' horrifyingkilling Flyerseps Hardingwiceventsserviceimum Oversiked angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 8/500 [00:04<03:44,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8] L-rel: 19.25660 / L-dis: 18.91409 / Best: 18.91409\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Signsoberifies comparisonTOlivion 163ques Valencia Bookviews™ Leg', ' horrifyingkilling Flyerseps Hardingwiceventsserviceimum Overses angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 9/500 [00:04<03:42,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[9] L-rel: 19.24364 / L-dis: 18.89674 / Best: 18.89674\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Signsoberifies comparisonTOlivion 163ques Valencia Bookes™ Leg', ' horrifyingkilling Wizardseps Hardingwiceventsserviceimum Overses angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 10/500 [00:04<03:40,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10] L-rel: 19.22980 / L-dis: 18.87298 / Best: 18.87298\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsoberifies comparisonTOlivion 163ques Valencia Bookty™ Leg', ' horrifyingkilling Wizardseps Hardingwiceventsserviceimum Overs.. angledATCH']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 11/500 [00:05<03:38,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11] L-rel: 19.21559 / L-dis: 18.84979 / Best: 18.84979\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsoberifies comparisonTOlivion 163ques Valencia Bookty™ Leg', ' horrifyingkilling Wizardseps Hardingwicevents FACimum Overs.. angled Cir']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 12/500 [00:05<03:37,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12] L-rel: 19.20064 / L-dis: 18.83702 / Best: 18.83702\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsoberifies comparisonTOlivion 163ques Valencia Bookty™ Disc', ' horrifyingkilling Wizardseps Hardingwicevents FACimum Overs.. angled Cir']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 13/500 [00:06<03:37,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13] L-rel: 19.18518 / L-dis: 18.83395 / Best: 18.83395\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsoberifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizardseps Hardingwicevents FACimum Overs.. angled Cir']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 14/500 [00:06<03:36,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14] L-rel: 19.17035 / L-dis: 18.83046 / Best: 18.83046\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsoberifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizards Simulator Hardingwicevents FACimum Oversount angled Cir']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 15/500 [00:07<03:35,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15] L-rel: 19.15616 / L-dis: 18.82809 / Best: 18.82809\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsenersifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizards International Hardingwicevents FACimum Oversty angled Cir']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 16/500 [00:07<03:35,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16] L-rel: 19.14327 / L-dis: 18.82551 / Best: 18.82551\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', 'ationsenersifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizards International Hardingwicevents FACimum Oversty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 17/500 [00:08<03:34,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17] L-rel: 19.13211 / L-dis: 18.82234 / Best: 18.82234\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' fansenersifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizards International Hardingwicevents FACimum Oversty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 18/500 [00:08<03:34,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[18] L-rel: 19.12268 / L-dis: 18.82039 / Best: 18.82039\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' fansenersifies comparisonTOlivion 163quesLie Bookty™ Disc', ' horrifyingkilling Wizards International Hardingwicevents FACimum Oversty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 19/500 [00:08<03:33,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19] L-rel: 19.11495 / L-dis: 18.81638 / Best: 18.81638\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remasteredenersifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards International Hardingwicevents FACimum Oversty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 20/500 [00:09<03:33,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20] L-rel: 19.10879 / L-dis: 18.81598 / Best: 18.81598\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards International Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 21/500 [00:09<03:32,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21] L-rel: 19.10400 / L-dis: 18.81773 / Best: 18.81598\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards International Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 22/500 [00:10<03:32,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22] L-rel: 19.10035 / L-dis: 18.81291 / Best: 18.81291\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 23/500 [00:10<03:32,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23] L-rel: 19.09764 / L-dis: 18.81068 / Best: 18.81068\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▍         | 24/500 [00:11<03:31,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[24] L-rel: 19.09568 / L-dis: 18.80756 / Best: 18.80756\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 25/500 [00:11<03:31,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[25] L-rel: 19.09430 / L-dis: 18.80512 / Best: 18.80512\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 26/500 [00:12<03:30,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[26] L-rel: 19.09341 / L-dis: 18.80457 / Best: 18.80457\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 27/500 [00:12<03:30,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[27] L-rel: 19.09288 / L-dis: 18.80494 / Best: 18.80457\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 28/500 [00:12<03:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[28] L-rel: 19.09262 / L-dis: 18.80624 / Best: 18.80457\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 29/500 [00:13<03:29,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[29] L-rel: 19.09257 / L-dis: 18.80624 / Best: 18.80457\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 30/500 [00:13<03:28,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[30] L-rel: 19.09256 / L-dis: 18.80511 / Best: 18.80457\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 31/500 [00:14<03:28,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[31] L-rel: 19.09251 / L-dis: 18.80368 / Best: 18.80368\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 32/500 [00:14<03:28,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[32] L-rel: 19.09229 / L-dis: 18.80240 / Best: 18.80240\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents WorldimumSecretty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 33/500 [00:15<03:27,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[33] L-rel: 19.09180 / L-dis: 18.80496 / Best: 18.80240\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards Simulator Hardingwicevents Worldimumoinety angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 34/500 [00:15<03:27,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[34] L-rel: 19.09112 / L-dis: 18.80616 / Best: 18.80240\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Wizards World Hardingwicevents Worldimumoinety angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 35/500 [00:16<03:26,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[35] L-rel: 19.09029 / L-dis: 18.80452 / Best: 18.80240\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Simulator World Hardingwicevents Worldimum issty angled CON']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 36/500 [00:16<03:26,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[36] L-rel: 19.08939 / L-dis: 18.80031 / Best: 18.80031\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163quesLie Bookty™ Emb', ' horrifyingkilling Simulator World Hardingwicevents Cameimum issty angled cons']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 37/500 [00:16<03:26,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[37] L-rel: 19.08830 / L-dis: 18.79609 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered Throneifies comparisonTOlivion 163 WorldLie Bookty™ Emb', ' horrifyingkilling Simulator World Hardingwicevents Cameimum issty angled Cons']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 38/500 [00:17<03:25,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[38] L-rel: 19.08701 / L-dis: 18.80056 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' Remastered stewardsifies comparisonTOlivion 163 WorldLie Bookty™ Emb', ' horrifyingkilling Simulator World Hardingwicevents Cameimum issty angled Cons']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 39/500 [00:17<03:25,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[39] L-rel: 19.08536 / L-dis: 18.80788 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' of stewards Wizards comparisonTOlivion 163 WorldLie Bookty™ Emb', ' horrifyingkilling WORLD World Hardingwicevents Cameimum iss Subject angled Cons']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 40/500 [00:18<03:24,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[40] L-rel: 19.08295 / L-dis: 18.81739 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnologyAugust Fuckrd Interestingly redund darling downgrade Vista Dru', ' of Remastered Wizards comparisonTOlivion 163 WorldLie Bookty™ Emb', ' horrifyingkilling WORLD World World Worldevents Cameimum iss cover angled Cons']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 41/500 [00:18<03:24,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[41] L-rel: 19.08002 / L-dis: 18.83356 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology cardinal Fuckrd Interestingly redund darling downgrade Vista Dru', ' of Remastered Wizards comparisonTOlivion 163 WorldLie Bookty™ Emb', ' ofkilling WORLD World World Worldevents Cameimum iss cover angled bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 42/500 [00:19<03:23,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[42] L-rel: 19.07669 / L-dis: 18.84015 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology cardinal Fuckrd Interestingly redund darling downgrade Vista Dru', ' of Remastered Wizards comparisonTOlivion 163 WorldLie Bookty™ Emb', ' of VR WORLD World World Worldevents Cameimum ye cover angled bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 43/500 [00:19<03:23,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[43] L-rel: 19.07301 / L-dis: 18.84358 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology SOC Fuckrd Interestingly redund darling downgrade Vista Dru', ' of Remastered Wizards comparisonTOlivion 163 aLie Book cover™ cons', ' of VR WORLD World World Worldevents hastimum ye cover angled bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 44/500 [00:20<03:23,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44] L-rel: 19.06898 / L-dis: 18.85608 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology SOC Fuckrd Interestingly redund darling downgrade Vista 383', ' of Remastered Wizards comparisonTOlivion 163 a lett Book cover FIL bound', ' of VR WORLD HERO World Worldevents hastimum cover cover angled bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 45/500 [00:20<03:22,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[45] L-rel: 19.06404 / L-dis: 18.89236 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology restraint Fuckrd Interestingly redund darling downgrade Vista 383', ' of Remastered Wizards comparisonTOlivion World a lett Book cover FIL bound', ' of VR Simulator HERO World WorldS hastimum cover version FIL bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 46/500 [00:20<03:22,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46] L-rel: 19.05723 / L-dis: 18.93761 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology restraint Fuck restraint Interestingly redund darling downgrade Vista disciplined', ' of Remastered Wizards comparisonTOlivionS- rip Book cover board status', ' of Simulator Simulator HERO HERO WorldS hastimum cover version IS bound']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 47/500 [00:21<03:21,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[47] L-rel: 19.04795 / L-dis: 18.95912 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology restraint Fuck Circuit Interestingly redund darling downgrade Vista disciplined', ' of Remastered Wizards comparisonTOlivionS- rip Book cover board status', ' of World Simulator Redux HERO WorldS Dissimum cover version bindapp']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 48/500 [00:21<03:21,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[48] L-rel: 19.03497 / L-dis: 18.98449 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology restraint Fuck Circuit Interestingly redund darling downgrade Contact disciplined', ' of Remastered Wizards UniverseTOlivionS- rip Book cover board status', ' of World Wizards Redux UnleashedIONSS Dissimum drinking version bindapp']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 49/500 [00:22<03:20,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[49] L-rel: 19.01924 / L-dis: 18.99705 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology restraint Fuck Circuit Interestingly redund darling downgrade Contact disciplined', ' of Remastered Wizards UniverseTOlivion Sins- rip Book body board status', ' of Worldocracy Redux UnleashedIONSIONS chargimum drinking version bindapp']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 50/500 [00:22<03:20,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50] L-rel: 19.00091 / L-dis: 19.00377 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology SOC Fuck Circuit Interestingly redundsc distribution Contact disciplined', ' of Simulator Wizards UniverseTOlivion Sins- rip Book body board status', ' of Worldocracy Redux UnleashedIONSIONS charg rip drinking version bind repl']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 51/500 [00:23<03:19,  2.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[51] L-rel: 18.98049 / L-dis: 19.01468 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology SOC Fuck Circuit Interestingly redundsc distribution Contact disciplined', ' of World Wizards UniverseTO Remastered Sins. rip Book body board status', ' of Worldocracy Redux UnleashedIONSides charg rip drinking version bind repl']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 52/500 [00:23<03:19,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[52] L-rel: 18.95873 / L-dis: 19.02169 / Best: 18.79609\n",
            " |- Curr: [' Casesrise seriousotechnology SOC Fuck Circuit Interestingly redundsc distribution Contact disciplined', ' of World Universe UniverseTO RemasteredION. rip Book extra board status', ' of Nationsocracy Redux AddictionIONSides charg rip drinking version bind heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 53/500 [00:24<03:19,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[53] L-rel: 18.93684 / L-dis: 19.03393 / Best: 18.79609\n",
            " |- Curr: [\"olsrise reciprocotechnology restraint Fuck Circuit Interestingly redundsc distribution Contact':\", ' of World Redux UniverseTO RemasteredIONIONS rip Book extra board status', ' Remastered Nationsocracy Redux AddictionIONSides chargπ drinking version bind heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 54/500 [00:24<03:18,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[54] L-rel: 18.91504 / L-dis: 19.04444 / Best: 18.79609\n",
            " |- Curr: [\"olsrise restraints restraint restraint Circuit Circuit Interestingly redundsc distribution Contact':\", ' of World Planetary UniverseTO RemasteredIONIONS rip Book extra board status', ' Remastered Nationsocracy Redux AddictionIONSides charg SERV drinking version bind heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 55/500 [00:24<03:18,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[55] L-rel: 18.89294 / L-dis: 19.05375 / Best: 18.79609\n",
            " |- Curr: [\"olsrise restraints restraint restraint Circuit Circuit Interestingly redundsc distribution Contact':\", ' Nations World Planetary AnimatedTO Kind�IONS Cover Book may board status', ' Remastered Nationsocracy Redux AddictionIONSides Cart Serv drinking version bind heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 56/500 [00:25<03:17,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[56] L-rel: 18.87146 / L-dis: 19.06814 / Best: 18.79609\n",
            " |- Curr: [\"olsrise restraints braces braces Circuit Circuit cycle redundsc distribution Contact':\", ' Nations World Planetary StellarTO Kind�IONS Cover Book may board status', ' Remastered Nationsocracy Redux AddictionIONSION Cart Serv drinking version bind heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 57/500 [00:25<03:17,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[57] L-rel: 18.85143 / L-dis: 19.06616 / Best: 18.79609\n",
            " |- Curr: [\"olsrise restraints braces Vac Circuit Circuit cycle RISsc nipple probes':\", ' Nations World Planetary StellarTO Kind�IONS repro Book may board status', ' Remastered Nationsocracyilogy AddictionIONSION Cart Serv drinking version VERS heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 58/500 [00:26<03:16,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[58] L-rel: 18.83123 / L-dis: 19.07222 / Best: 18.79609\n",
            " |- Curr: [\"olsrise restraints braces Vac Circuit Circuit cycle RISscelectric Contact':\", ' Nations World Planetary StellarTO Kind�ers repro Book may boardimm', ' Remastered Nationsocracyocracy AddictionIONSION Cart Serv data version PART heck']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 58/500 [00:26<03:23,  2.17it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_float32_matmul_precision(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 3e49204e93ec17121e9c5a5d1021cc08b5c14d09\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Start Attack ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     loss, best_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_toke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwandb_logging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_loss_sample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Done. Final loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m.\u001b[39mmean())\n",
            "Cell \u001b[0;32mIn[6], line 79\u001b[0m, in \u001b[0;36mattack\u001b[0;34m(model, tokenizer, config, loss_func, verbose, discrete_loss_sample_rate)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     78\u001b[0m     activations_discrete \u001b[38;5;241m=\u001b[39m (model(all_tokens))[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 79\u001b[0m     discrete_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations_discrete\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     avg_loss_i, avg_best_loss \u001b[38;5;241m=\u001b[39m discrete_loss\u001b[38;5;241m.\u001b[39mmean(), best_loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m avg_loss_i \u001b[38;5;241m<\u001b[39m avg_best_loss:\n",
            "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mreturn_maximise_logit_entropy_distribution.<locals>.<lambda>\u001b[0;34m(activations)\u001b[0m\n\u001b[1;32m     36\u001b[0m _model, _ \u001b[38;5;241m=\u001b[39m get_model_wrapper(model_id, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     37\u001b[0m unembedding_weights \u001b[38;5;241m=\u001b[39m _model\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\n\u001b[0;32m---> 38\u001b[0m _loss_wraper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m activations: \u001b[43mmaximise_entropy_distribution_of_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munembedding_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_safety\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumerical_safety\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _loss_wraper\n",
            "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mmaximise_entropy_distribution_of_logits\u001b[0;34m(activations, unembedding_weights, numerical_safety)\u001b[0m\n\u001b[1;32m     27\u001b[0m p_activations \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(logits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-4\u001b[39m) \u001b[38;5;241m/\u001b[39m normaliser\n\u001b[1;32m     28\u001b[0m log_p_activations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(p_activations)\n\u001b[1;32m     29\u001b[0m losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mkl_div(log_p_activations, \\\n\u001b[0;32m---> 30\u001b[0m                            \u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_activations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mp_activations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, \\\n\u001b[1;32m     31\u001b[0m                                     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# preserves batch dims\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "    main()\n",
        "# 3e49204e93ec17121e9c5a5d1021cc08b5c14d09"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_Yp5wMH2vvI"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "\n",
        "# time.sleep(64)\n",
        "\n",
        "# from google.colab import runtime\n",
        "# runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjl_LBjY2zJH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
